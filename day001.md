# DAY001 - Deep Learning 원리

DL / LAYER / EPOCH / BATCH / LOSS / MSE / MAE / RMSE / RMAE / Linear Regression



## 1. Deep Learning 원리

<img width="1000" alt="스크린샷 2020-01-23 오전 1 06 59" src="https://user-images.githubusercontent.com/31688871/72945771-36c33780-3dc0-11ea-8f9e-df80951b9c19.png">

고양이가 생선을 보자마자 고양이의 뇌 속에서는 부교감신경세포들이 폭동을 일으키며 고양이 침샘을 자극하여 침을 흘리게 한다.이 상황을 Deep Learning 관점으로 치환하자면 아래 그림과 같이 된다.

<img width="1000" alt="스크린샷 2020-01-23 오전 12 40 49" src="https://user-images.githubusercontent.com/31688871/72947656-17c7a400-3dc6-11ea-8613-609813a3adb0.png">

생선은 데이터로서 Input 역할 / 침은 결과로서 Output 역할 / 고양이 뇌는 Input에서 Output으로 연결시켜는 학습과정 역할이다. 좀 더 이론적으로 말하면 **Deep Learning은 Input / Hidden / Output Layer로 구성**이 되어 있다. 

------------------

<img width="1000" alt="스크린샷 2020-01-23 오전 12 57 00" src="https://user-images.githubusercontent.com/31688871/72947707-3c238080-3dc6-11ea-9a4f-8fe4a88bec9a.png">

--------------------



레이어(Layer)는 노드(Node)라는 것들로 이루어져 있으며 각 노드들은 학습 후에 다음 레이어의 노드들로 넘어간다. 레이어가 많아져 연결된 노드의 개수가 증가할수록 복잡해지지만 그만큼 학습을 **깊게** 할 수 있다. 그래서 위의 그림처럼 레이어 개수가 많아질수록 깊어진다고 하여 Learning앞에 Deep이 붙은 것이다.



## 2. Deep Learning 매커니즘

<img width="1000" alt="스크린샷 2020-01-23 오전 1 04 55" src="https://user-images.githubusercontent.com/31688871/72956877-cda1eb00-3de4-11ea-86b4-07e53f9ce11f.png">

기본적으로 데이터를 정제하는 데이터처리 과정을 거쳐 학습시킬 모델을 구성 후에 처리된 데이터를 훈련시킨다. 그 다음에 제대로 훈련되었는지 평가하고 테스트 데이터를 통해 예측을 실시한다.

아래는 x = 1-10, y = 1-10인 데이터를 가지고 구현한 딥러닝 코드이다.

```python
import numpy as np
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense

x = np.array([1,2,3,4,5,6,7,8,9,10])
y = np.array([1,2,3,4,5,6,7,8,9,10])

model = Sequential()

model.add(Dense(5, input_dim = 1))

model.add(Dense(2))
model.add(Dense(3))
model.add(Dense(1))

model.summary()

model.compile(loss = 'mse', optimizer='adam', metrics=['mse']) 
model.fit(x,y,epochs = 100, batch_size=1) 

loss, mse = model.evaluate(x,y,batch_size=1)
print('mse:', mse)

x_prd = np.array([11,12,13])
test = model.predict(x_prd, batch_size=2)
print(test)
```

단계별로 쪼개서 코드를 보자~!

### [0] 필요한 모듈 불러오기

```python
import numpy as np
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense
```

먼저 딥러닝 과정에 필요한 모듈을 미리 불러온다.

### [1] 처리된 데이터 준비

```python
x = np.array([1,2,3,4,5,6,7,8,9,10])
y = np.array([1,2,3,4,5,6,7,8,9,10])
```

원래는 완전 Raw한 데이터를 정제하는 과정이 정석이지만 데이터가 정제되었다는 가정하에 np.array()로 1차원 데이터를 불러온다.

### [2] 모델구성

```python
model = Sequential() # Sequential 모델은 레이어를 선형으로 연결하여 구성

model.add(Dense(5, input_dim = 1))#-Input Layer

model.add(Dense(2))#----------------Hidden Layer 1
model.add(Dense(3))#----------------Hidden Layer 2

model.add(Dense(1))#----------------Output Layer

model.summary()#레이어의 shape과 Parameter 보기
```

데이터를 학습시킬 모델을 구성한다. `model = Sequential()`로 구성할 모델 방식을 선언해준다. Sequential 모델은 레이어를 선형으로 연결하여 구성하는 방식이다. 다음으로 `model.add(Dense(노드 개수, 인풋 데이터 차원 = ))`으로 Input Layer를 구성해주고 그 아래에는 같은 방식으로 `model.add(Dense(노드 개수))` 를 추가하여 Hidden Layer와 노드 개수를 원하는 만큼 추가한다. 단 적당한 너무 레이어와 노드수는 학습이 완료되는 시간에 영향을 미치므로 학습데이터 양에 따라 적당하게 입력하는 것이 좋다. 그 다음 마지막 `model.add(Dense(1))` 으로 Output Layer로 마무리를 지어준다. Output은 결과가 하나이므로 노드 개수가 1이 되는 것이다.



<img width="1288" alt="스크린샷 2020-01-23 오전 1 46 16" src="https://user-images.githubusercontent.com/31688871/72976011-1d000f80-3e15-11ea-857d-117ca154c60f.png">



#### [3] 훈련

```python
model.compile(loss = 'mse', optimizer='adam', metrics=['mse']) 
model.fit(x,y,epochs = 100, batch_size=1) 
```

`model.compile(loss = , opimizer = , metrics = )` 는 학습의 과정을 설정하는 함수이다. 쉽게 말하면 컴퓨터가 이해할 수 있는 언어로 바꿔주는 작업이라고 생각하면 된다. 

**loss :** 훈련 과정에서 사용할 손실 함수(lost function)를 설정

**optimizer :** 훈련 과정을 설정하는 옵티마이저를 설정. 'adam'이나 'sgd'와 같이 문자열로 지정 가능 

**metrics :** 훈련을 모니터링하기 위한 지표를 선택

`model.fit(x 데이터, y 데이터, epochs=100, batch_size=10)` 는 데이터를 가지고 모델을 학습시킨다. 



#### [4] 평가

```python
loss, mse = model.evaluate(x,y,batch_size=1)
print('mse:', mse)
```

**evaluate()** : 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가합니다.

```python
# 위의 fit() 코드의 연장선상인 코드
model.evaluate(X_test, y_test, batch_size=32)
```

**첫번째 인자** = 테스트 데이터에 해당됩니다.
**두번째 인자** = 지도 학습에서 레이블 테스트 데이터에 해당됩니다.
**batch_size** = 배치 크기.

**predict()** : 임의의 입력에 대한 모델의 출력값을 확인합니다.



#### [5] 예측

```python
x_prd = np.array([11,12,13])
test = model.predict(x_prd, batch_size=2)
print(test)
```

```
model.predict(X_input, batch_size=32)
```

**첫번째 인자** = 예측하고자 하는 데이터.
**batch_size** = 배치 크기


